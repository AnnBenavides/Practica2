# 05122017 -> Investigación pt.2

## Sobre Desarrollo de Testing
[Fuente](http://searchsoftwarequality.techtarget.com/answer/How-to-conduct-performance-stress-load-testing-without-tools)

### 2. Test Performance
- [x] [**Evaluar el espacio de trabajo**](https://github.com/AnnBenavides/Practica2/blob/master/Bitacora/04122017.md#2-test-performance)
- [ ] **Construir los temas a evaluar con los test** "escenificar" el entorno (enviroment), identificar datos, construir los scripts y calibrar los test

	***Entender y manejar las herramientas y entornos de testeo:*** el manejo del sistema/aplicación a testear, el manejo de las herramientas de apoyo de monitoreo y debuggin, y el manejo de herramientas de apoyo a la ejecución del PT; en cada una de estas áreas se debe identificar lo que es necesario, instalar el software y hardware requerido, y configurarlo para calzar con el proyecto y coordinar el cómo se usará en el futuro. Hacer la siguiente tabla ayudará a pensar sobre todo lo que se necesitará para el éxito, algunas preguntas serán resueltas con compras, otras con procesos y algunas podrían quedar sin respuesta.

	![Tabla1](http://cdn.ttgtmedia.com/digitalguide/images/Misc/md_tc.jpg)

	***Identificar, crear y administrar los datos de testeo***
	- _Seleccionar datos basado en el riesgo:_ cuando identificamos riesgos buscamos qué podría ir mal, podemos usar la nemotecnia FIBLOTS:
		- **F**requent -> ¿Qué datos son los más utilizados? (login id, reference data, etc)
		- **I**ntensive -> ¿Qué datos son pesados? (wildcard searches, subir archivos pesados, valores que requieren conversión, etc)
		- **B**usiness critical -> ¿Qué datos apoyan procesos que representan lo que el "negocio" necesita para trabajar? (procesos a fin de mes, creación de nuevas cuentas, etc)
		- **L**egal -> ¿Qué datos apoyan procesos que son requeridos para trabajar por contrato?
		- **O**bvious -> ¿Qué datos apoyan procesos que nos darán mala fama si no funcionan?
		- **T**echnically risky -> ¿Qué datos son apoyadfos o interactuan con aspectos técnicos riesgosos del sistema? (nuevas o viejas tecnologías, lugares que han fallado antes, etc)
		- **S**takeholder-mandated -> ¿Qué datos se han dicho/consultado para que tengan un test?
	- _Seleccionar datos basado en los escenarios de testeo:_ necesitaremos seleccionar datos que permitan testear escenarios específicos con los modelos de usabilidad y _test scenarios_ 
	- _Seleccionar datos basados en disponibilidad:_ la idea aquí es la data es de fácil acceso, así como usable y significativa, entonces incluirla en el PT puede salvar tiempo y dinero (como datos de las iteraciónes pasadas, datos de otros poryectos involucrados, odatos generados)
	- _Usar datos producidos:_ si bien no buscamos apoyarnos sólo en estos datos, estos pueden formar el escenario más rico para el testeo (realista), así como puede ser útil para afinar y debuggear el sistema desde la perspectiva de funcionalidad. Ahora, su debilidad es que puede que no contenga los casos especiales que quisieramos testear por lo que no sería un escenario completo.
	- _Usar datos generados:_ muchas herrameintas usan datos generados, son utiles ya que te permiten sets grandes de datos que sigan cierto patrón. Con esto puedes cubrir los casos especiales que no cubres con los datos producidos.

	Una vez identificado tus datos, piensa sobre el formato que necesitarás en que estén esos datos (XML, plainText, database, etc), si necesitarán algún tipo de procesamiento o conversión. También piensa sobre cómo administrarás estos datos multiplas versiones sueltas, ¿querrás juntar los datasets? Además hay que analizar la dependencia de estos datos, de haber, habrá observar si nuestras herramientas y procesos de desarrollo soportan la evolución de los datos.

	***Code your test scripts***

	***Calibrar los modelos de workload***
	- Cambiando los tiempos y delays
	- Cambiando el número de usuarios en el test o porcentaje de uso del modelo
	- Cambiando el tiempo de aceleración del usuario
	- Cambiando el nro de iteraciones y tiempo entre ellas
	- Cambiando los escenarios o datos de testeo

	***Al final de esta fase:***

- [ ] **Entregar la información** correr los test, analizar resultados, hacerlos significativos para el equipo y trabajar en el proceso de afinamiento.

### 3. Software Performance Testing
- **Decidir que escenarios incluir en un test de funcionalidad**
- **Mejora con un buen reporte de bug's**

### 4. Qué incluir en un plan de PT.
Cómo el PT procederá desde la prespectiva "de negocios" a la técnica.  

### 5. SCORN para testear el front end de un website
El front end contiene más oportunidades de mejoras de comportamiento grandes y baratas.

## Recomendados por Cristian R.
**Test de stress**
- [ ] JMeter
- [ ] AB para servidores

**Test de funcionalidad**
- [ ] [Selenium](http://www.seleniumhq.org/)
- [ ] [Katalon](https://www.katalon.com/)

**Test de Seguridad**
- [ ] [Nikto](https://cirt.net/Nikto2)
- [ ] [AP/OWASP](https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project)
- [ ] [Metasploit](https://www.metasploit.com/)
